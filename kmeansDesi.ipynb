{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Engineering Bootcamp - Level 3 Task 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''' For the kMeans clustering problem for this task I followed the outline in the pdf and also used the shell template\n",
    "provided in this task. Essentially I followed 5 steps and then finally put it all together. \n",
    "Part 0 - I imported all the required python libraries\n",
    "Part 1 - I defined a function to read in the csv file as a pandas dataframe\n",
    "Part 2 - I defined a function to calculate the euclidean distance between points\n",
    "Part 3 - I defined a function to randomly select centroids based on the number of cluster chosen by the user\n",
    "Part 4 - I wrote a function to assign each point to a cluster (based on the current centroids coordinates) and I also wrote\n",
    "a function to return the sum of the euclidean distance between the points and their chosen cluster or centroid\n",
    "Part 5 - I wrote teh Kmeans algotrith to update the centroids based on the points assigned to the cluster. the centroids \n",
    "were updated to mean of the points closest to it.\n",
    "\n",
    "Lastly I put all the functions together to determine the cluster that each point belongs to aswell plot the scatter graph.'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''' Part 0: Import Libraries '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy allows us to do the math to the data\n",
    "import numpy as np\n",
    "\n",
    "# Numpy allows us to do dataframe and matrix computations\n",
    "import pandas as pd\n",
    " \n",
    "# Seaborn allows us to plot the graphs when it is time to plot nearer to the end of this task\n",
    "import seaborn as sns\n",
    "\n",
    "# And Finally random, because we use random to find and initialize the clusters that we need to calculate the distance to\n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Part I : We know that there are 3 datasets we need to be able to read when the user decides. So first we should create\n",
    "        a function that allows us to read any of the three csv files (Keep in mind that Birthrate is x and Life Expectancy\n",
    "                                                                      is y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function with one argument since we will be using a csv file to be able to... Well, y'know. Read the file.\n",
    "# The read file should also be returned as a list for use within our calculations. This can also be done outside this function\n",
    "\n",
    "#For this function I imported the data as a pandas dataframe\n",
    "\n",
    "def readCSV(file):\n",
    "    \n",
    "    df = pd.read_csv(file, delimiter=',')\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "We are now able to read whichever file the user chooses. Now we get into the mathematical part of things. (No worries,\n",
    "    numpy makes this easy for us)\n",
    "\n",
    "Part II : Finding the Euclidean distance between any two points. This is one of the math parts of the task\n",
    "            The PDF contains what the Eucliedian distance calculation it is. It's up to you for how the calculation is done\n",
    "                in Python, HINT : np.sqrt allows you to calculate the square root of a value.\n",
    "                    Also keep in mind that you can use nested loops to separate x1 and x2 and y1 and y2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this function I calculated the distance using the lambda function and applying it the pandas dataframe. The pandas\n",
    "# is essentially the data from the csv file that was read in. The read function above imports the data as a dataframe.\n",
    "\n",
    "def euclideanDistCalc(arr, x1, y1):  \n",
    "        \n",
    "    arr.columns = ['countries', 'birthRate', 'lifeExpectancy']\n",
    "    arr = arr.assign(sumProduct=lambda x: (((x['birthRate'] - x1)**2 + (x['lifeExpectancy'] - y1)**2)**0.5))\n",
    "\n",
    "    result = arr['sumProduct'].values\n",
    "    \n",
    "    del arr['sumProduct']\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Part III : Initalizing the Clusters. This part is determined by the amount of clusters the user wants in their analysis. \n",
    "        This can be done easily by creating two empty lists and appending (using a for loop) the data from the actual dataset (we can refer to this in \n",
    "\tour function as strList) then we append this data to our empty X and Y lists and use .random to take a random sample for our cluster initialization.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below function randomly picks points in our data as our initial centroids. The number of centroids chosen is equal\n",
    "#to the number of clusters selected by the user.\n",
    "\n",
    "def initCentroids(arr, numClusters):\n",
    "    \n",
    "    random.seed(42)\n",
    "    \n",
    "    arr.columns = ['countries', 'birthRate', 'lifeExpectancy']\n",
    "    rows = len(arr)\n",
    "   \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(0,numClusters):\n",
    "        j = random.randint(0,rows)\n",
    "        x.append(arr['birthRate'][j])\n",
    "        y.append(arr['lifeExpectancy'][j])\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Part IV : The below two functions essentially returns the cluster that the respective point belongs to (returnCluster). In\n",
    "addition I've also defined a function to calculate the sum of the euclidean distance for all the points (returnDist). I will\n",
    "use the second function to check for convergence.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For a given dataframe and a set of centroids, the below function calculates the cluster the point belongs to.\n",
    "\n",
    "def returnCluster(arr, a, b):\n",
    "    arr.columns = ['countries', 'birthRate', 'lifeExpectancy']\n",
    "    count = len(a)\n",
    "    rows = len(df)\n",
    "    \n",
    "    temp = pd.DataFrame()\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        temp['dist'+str(i)] = euclideanDistCalc(arr, a[i], b[i])\n",
    "\n",
    "    cluster = []\n",
    "    \n",
    "    for k in range(0, rows):\n",
    "        group = np.argmin(temp.iloc[k].values)\n",
    "        cluster.append(group)\n",
    "    \n",
    "    return cluster\n",
    "\n",
    "\n",
    "#The below function determines the sum of the euclidean distances for each point in the dataset\n",
    "\n",
    "def returnDist(arr, a, b):\n",
    "    arr.columns = ['countries', 'birthRate', 'lifeExpectancy']\n",
    "    count = len(a)\n",
    "    rows = len(df)\n",
    "    \n",
    "    temp = pd.DataFrame()\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        temp['dist'+str(i)] = euclideanDistCalc(arr, a[i], b[i])\n",
    "\n",
    "    dist = 0\n",
    "    \n",
    "    for k in range(0, rows):\n",
    "        group = np.min(temp.iloc[k].values)\n",
    "        dist += group\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Part V : And finally for our last bit, we'll be implementing the kMeans algorithm. This can be really easy (with proper research) or you can be \n",
    "\textra and create a function yourself! \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essentially what this function does is determine the cluster for each point and based on this it then determines the mean\n",
    "#for each points belonging to a specific centroid. The centroids are then updated with the mean values.\n",
    "\n",
    "\n",
    "def kMeansAlg(arr, a, b):\n",
    "    #    # If you're feeling tough\n",
    "    count = len(a)\n",
    "\n",
    "    cluster = returnCluster(arr, a, b)\n",
    "\n",
    "    arr['cluster'] = cluster\n",
    "        \n",
    "    for j in range(0, count):\n",
    "        a[j] = (arr[(arr['cluster'] == j)])['birthRate'].mean()\n",
    "        b[j] = (arr[(arr['cluster'] == j)])['lifeExpectancy'].mean()\n",
    "        \n",
    "\n",
    "    del arr['cluster']\n",
    "    \n",
    "   \n",
    "    return a, b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Finally :We put all the functions defined above together to come up with our k-Means Clustering Algorithm.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ask user for the file they want to import\n",
    "dataSet1 = input('''Plese enter the file name you want to use: data1953.csv, data2008.csv or dataBoth.csv: ''' )    \n",
    "                                                                                        \n",
    "# Asks user for the number of clusters the want to split the data into\n",
    "cluster_amount = int(input(\"Input cluster amount: \")) \n",
    "\n",
    "#Here we read in the file as a pandas dataframe and rename the columns so that its easier to use.\n",
    "df = readCSV(dataSet1)\n",
    "df.columns = ['countries', 'birthRate', 'lifeExpectancy']\n",
    "\n",
    "#Init Centroids\n",
    "a, b = initCentroids(df, cluster_amount)\n",
    "\n",
    "#Init sum of the euclidean distance between each point in the dataset\n",
    "dist = returnDist(df, a, b)\n",
    "\n",
    "#The below variable will represent our iteration counter\n",
    "maxIterations = 0\n",
    "\n",
    "#Now we perform iterations to determine the optiomal centroids\n",
    "#Essentially here update the centroids until the sum of the euclidean distance between the points does not improve or \n",
    "#the max number of interations doesn't exceed 20. The last part is there to ensure that we don't have an infinite loop.\n",
    "while maxIterations <= 20:\n",
    "    a,b = kMeansAlg(df, a , b)\n",
    "    if (dist == returnDist(df, a, b)):\n",
    "        break\n",
    "    else:\n",
    "        dist = returnDist(df, a, b)\n",
    "        maxIterations += 1    \n",
    "\n",
    "\n",
    "#Now based on our optimized centroids, we determine the cluster of each point in our dataset.\n",
    "clust = returnCluster(df, a, b)\n",
    "\n",
    "#Here I created a dictionary that will store the values/coordinates of the optmized centroids\n",
    "dict = {'X': a, 'Y': b}\n",
    "\n",
    "#Create a temporay dataframe that has the centroid coordinates\n",
    "temp = pd.DataFrame(data=dict)\n",
    "\n",
    "#the df['cluster'] column basically shows which cluster the point belongs to\n",
    "df['cluster'] = clust\n",
    "\n",
    "\n",
    "#Setup colour list for our clusters\n",
    "cmaps = [\"Blue\", \"Green\", \"Purple\", \"Pink\", \"Red\", \"Orange\", \"Brown\", \"Black\", \"Yellow\", \"Grey\"] \n",
    "colormap=cmaps[0:cluster_amount]\n",
    "\n",
    "markerColor = []\n",
    "color = 'Red'\n",
    "for i in range(0,len(a)):\n",
    "    markerColor.append(color)\n",
    "\n",
    "#Lastly we plot our data and colour each according to the cluster it belongs to\n",
    "#I also ploy the centroid\n",
    "print(\"\\n\\nCategorised ScatterPlot\\n\")\n",
    "\n",
    "sns.scatterplot('birthRate', 'lifeExpectancy', data=df, hue='cluster', palette=colormap)\n",
    "sns.scatterplot('X', 'Y', data=temp, hue=temp.index, s=100, palette=markerColor, marker='x', legend= False)\n",
    "\n",
    "#Finally delete the cluster columns and temp dataframe\n",
    "del df['cluster']\n",
    "del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
